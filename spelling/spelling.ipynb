{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e35e47c-01e8-4b75-8b93-a7047977e079",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install g2p-en regex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1109e18a-869d-4a2b-8db1-6d0ce10f17b2",
   "metadata": {},
   "source": [
    "# Goals\n",
    "\n",
    "My goals with this notebook is to provide some grounding for spelling in silabex.\n",
    "Each silabex character is constructed from:\n",
    "\n",
    "1) an initial consonant cluster which can have any 1 of 1024 combinations.\n",
    "2) a vowel cluster which can have any of 16 combinations.\n",
    "3) an optional final consonant which can also have any 1 of 1024 combinations.\n",
    "\n",
    "In stenography, the system this writing system was original based on, \n",
    "the 3 parts roughly correspond to: the `left hand`, the `vowel keys` at the thumb, and the `right hand`.  \n",
    "There are some differences between the two however, \n",
    "so I feel like `silabex` should have it's own spelling theory sepearte from `steno`.\n",
    "\n",
    "### spelling priorities\n",
    "\n",
    "My overall priorities when designing this spelling system are as follows:\n",
    "\n",
    "* Prioritize American english pronounciation. As this is my first langauge, I feel I can do a better job with this as the basis\n",
    "* Develop this spelling system to cleave more closely to modern pronunciation.  \n",
    "   It's my understanding that english pronunciation changed quite a bit \n",
    "   even after spellings started to standarize. [why-is-english-spelling-so-tricky](https://blog.duolingo.com/why-is-english-spelling-so-tricky/)  \n",
    "   It feels like this is a good a time as any to update standard spellings\n",
    "   since this writing system is so different from standard english.\n",
    "* Compress the most common words into as few characters as possible.\n",
    "   Even the english alphabet does not accurately represent the sounds required to reproduce a word. [chameleon](https://www.youtube.com/watch?v=-Fy_NYCtSgw)  \n",
    "   For the most common words, sacrificing accuracy for brevity seems like a reasonable trade off.\n",
    "   This priority does conflict with other priorities however, so it should likely only apply to a few thousand of the most common words at most.\n",
    "* Redundent graphmemes should be destroyed. kbye\n",
    "\n",
    "### what this project does not do\n",
    "/\n",
    "In order to prevent this project from becoming much larger,\n",
    "there are a few things that I don't intend to do included here:\n",
    "\n",
    "Out of Scope:\n",
    "\n",
    "* Replace aribic numerals with another numbering system.\n",
    "   It's an interesting idea to play around with, but it's beyond the scope of this project.\n",
    "* Fully standardize spelling in some meaningful way.\n",
    "   The goal is mostly to get a good start and provide some solid footing.\n",
    "   Fleshing out the spelling system is a much larger and much longer project to take on.\n",
    "* Seriously consider non-english words and how to handle them.\n",
    "   English is currently all over the place on this (Hors d'oeuvre anyone?) and other writing systems like Japanese have entier different writing systems for foreign words.\n",
    "   Integrating foreign, and loan words, as well as non english nouns into the writing system will be a whole different process.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fec3f8-3f19-4dbd-af55-780f01fe8e03",
   "metadata": {},
   "source": [
    "# Silabex\n",
    "\n",
    "Silabex is a new writing system for english that adopts an eastern athsetic and attempts to create more standard representations of words\n",
    "All characters are 1:1 and consist of the following structure:\n",
    "\n",
    "```sh\n",
    " -----------v-----------\n",
    " |                     |\n",
    " |    /  /     /  /    |\n",
    " |                     |\n",
    " |    ----    ----     |\n",
    " |    |  |    |  |     |\n",
    " v    -I--    --F-     v\n",
    " |    |  |    |  |     |\n",
    " |    ----    ----     |\n",
    " |                     |\n",
    " |    /  /    /  /     |\n",
    " |                     |\n",
    " -----------v-----------\n",
    " ```\n",
    "\n",
    "where the outer lines (marked by v) represent vowel sounds, the left set of strokes represent the initial consonant cluster and the right set of strokes represent the final consonant cluster.\n",
    "\n",
    "## Resources\n",
    "\n",
    "There are several things I want to take into consideration while doing this research:\n",
    "1) Phonemes - these are the `atoms of pronuciation`. These are particularly important for determining how to split up characters in `silabex`\n",
    "2) Graphmemes - these are the `atoms of spelling` (it's not just letters, combinations like sh, or ch are also technically atoms in this sense)\n",
    "\n",
    "#### NLTK\n",
    "\n",
    "nltk looks like it has a lot of useful tools that could help me analyse textual data\n",
    "\n",
    "#### cmudict\n",
    "\n",
    "Provides a method for converting words into phonemes.\n",
    "Can be found here https://www.nltk.org/_modules/nltk/corpus/reader/cmudict.html\n",
    "\n",
    "#### G2P-EN\n",
    "\n",
    "This looks like a great way to convert words into graphmemes.\n",
    "g2p-en can be found here https://pypi.org/project/g2p-en/\n",
    "\n",
    "#### Stenography\n",
    "\n",
    "This was the original inspiration for the `silabex` writing system.\n",
    "It splits words down into sylablx adjacent pieces and has a fairly limited keyboard with translates decently to character designs\n",
    "It's also what lead to the idea of breaking a character down into and initial consonant cluster, a vowel cluster, and an optional final consonant cluster.\n",
    "\n",
    "#### plover\n",
    "\n",
    "[Plover](https://www.openstenoproject.org/plover/) is the most open project providing information on stenography (which is a suprizingly closed off eco-system).\n",
    "\n",
    "My initial idea was to steal the plover steno theory directly, but I have a feeling that with a little bit of work I can come up with a system more suited to my writing system.\n",
    "The main point is that while in stento the S, and * keys are doubled up, that's not a necessary feature to carry over to `silabex`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd3adc-8057-45c5-b763-25715d5c5070",
   "metadata": {},
   "source": [
    "# Phonemes\n",
    "\n",
    "Let's start by investigating phoneme frequencies.\n",
    "It seems like g2p uses the phoneme descriptors defined in the [Carnegie Mellon Pronouncing Dictionary](https://www.nltk.org/_modules/nltk/corpus/reader/cmudict.html) so I want to see how frequent each of those phonemes tends to be.\n",
    "It also looks like this repo [dolph/dictionary](https://github.com/dolph/dictionary) is an easy place to start since I just have to basically use the text file.\n",
    "Let's clone that repo down and do some analisys.\n",
    "\n",
    "Looks like we can also grab all the words that were used in the Carnegie Mellon Dictionary so let's try doing that as well.\n",
    "\n",
    "### Analysis\n",
    "\n",
    "So it looks like there are a total of 15 vowels and 24 consonant phonemes.\n",
    "That's great becuase I can represent a total of 16 vowels and way more than 24 consonants.\n",
    "I know that consonants can appear in clusters though so I need to figure out what cluster are the most common.\n",
    "It also looks like most phonemes have an exponential fall of in how frequently they are used which was expected.\n",
    "\n",
    "I'm also realizing that the average American probalby only ever activly uses about 40k words max:\n",
    "* https://blog.cyracom.com/ciiblog/the-lifelong-pursuit-of-language-learning-how-the-vocabularies-of-native-and-non-native-speakers-compare\n",
    "* https://www.economist.com/johnson/2013/05/29/lexical-facts\n",
    "\n",
    "My dataset might honestly be too large.\n",
    "I should focus on improving the quality of word choice rather than trying to find more words to analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f71eb8c-034a-4560-b28c-c51987aa4406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'data/dictionary'...\n",
      "remote: Enumerating objects: 45, done.\u001b[K\n",
      "remote: Total 45 (delta 0), reused 0 (delta 0), pack-reused 45\u001b[K\n",
      "Receiving objects: 100% (45/45), 1.89 MiB | 4.69 MiB/s, done.\n",
      "Resolving deltas: 100% (16/16), done.\n"
     ]
    }
   ],
   "source": [
    "# force a fresh clone of the dolph/dictionary\n",
    "!rm -rf data/dictionary\n",
    "!git clone https://github.com/dolph/dictionary data/dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f85f0a4-5dcf-427f-b451-bd1581423940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing dictionary/popular.txt...\n",
      "got 25323 words\n",
      "Final Unique Word Total:  25323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['', 'aa', 'aardvark', 'aargh', 'aback', 'abacus', 'abandon',\n",
       "       'abandoned', 'abandoning', 'abandonment'], dtype='<U32')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "common_words = np.empty(0)\n",
    "for file in [\"dictionary/popular.txt\"]:\n",
    "    with open(f\"data/{file}\", \"r\") as f:\n",
    "        print(f\"importing {file}...\")\n",
    "        raw_words = f.read()\n",
    "        new_words = [ word.lower() for word in raw_words.split(\"\\n\") ]\n",
    "        print(f\"got {len(new_words)} words\")\n",
    "\n",
    "    common_words = np.append(common_words, new_words)\n",
    "\n",
    "common_words = np.unique(common_words)\n",
    "print(\"Final Unique Word Total: \", common_words.shape[0])\n",
    "common_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e3592-2cac-45eb-aa4e-2da62fb70057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Phoneme Lists: 100%|██████████████████████████████████████████████████████████████████████| 25323/25323 [06:35<00:00, 63.98it/s]\n",
      "Add cmudict Words:  13%|█████████▌                                                              | 16391/123455 [09:30<1:33:02, 19.18it/s]"
     ]
    }
   ],
   "source": [
    "from g2p_en import G2p\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import cmudict\n",
    "import re\n",
    "\n",
    "g2p = G2p()\n",
    "phoneme_list = np.empty(0)\n",
    "simple_phoneme_list = np.empty(0)\n",
    "for word in tqdm(common_words, desc=\"Building Phoneme Lists\"):\n",
    "    if word == \"\":\n",
    "        continue\n",
    "\n",
    "    out = g2p(word)\n",
    "    phoneme_list = np.append(phoneme_list, out)\n",
    "    simple_phoneme_list = np.append(simple_phoneme_list, [ re.sub('\\d+', \"\", i) for i in out ] )\n",
    "\n",
    "cmudict_words = cmudict.dict()\n",
    "for word in tqdm(cmudict_words, desc=\"Add cmudict Words\"):\n",
    "    if word == \"\":\n",
    "        continue\n",
    "\n",
    "    out = cmudict_words[word][0]\n",
    "    phoneme_list = np.append(phoneme_list, out)\n",
    "    simple_phoneme_list = np.append(simple_phoneme_list, [ re.sub('\\d+', \"\", i) for i in out ] )\n",
    "    \n",
    "display(np.unique(phoneme_list))\n",
    "display(np.unique(simple_phoneme_list))\n",
    "\n",
    "# save these so we don't have to recompute them every time\n",
    "with open(\"data/phoneme_list.npy\", \"wb\") as f:\n",
    "    np.save(f, phoneme_list)\n",
    "\n",
    "with open(\"data/simple_phoneme_list.npy\", \"wb\") as f:\n",
    "    np.save(f, simple_phoneme_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab6d631-046e-45af-bed8-b7a458034348",
   "metadata": {},
   "source": [
    "# Analyse the Data\n",
    "\n",
    "now that we've loaded the data all into memory we need to analyse it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd15eb9-d765-4b42-a203-9e6a369d8973",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/phoneme_list.npy\", \"rb\") as f:\n",
    "    phoneme_list = np.load(f)\n",
    "\n",
    "with open(\"data/simple_phoneme_list.npy\", \"rb\") as f:\n",
    "    simple_phoneme_list = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56cacb1-1851-4306-8dcb-1ed236af6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(30, 6))\n",
    "plt.hist(phoneme_list, bins='auto')\n",
    "plt.title(f\"Phoneme Frequency In {common_words.shape[0]} Common Words\")\n",
    "plt.xlabel(\"phoneme\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b297e31d-fcf3-42b0-add1-feb76ba92bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_phoneme_chart(phonemes, title, x_axis, y_axis):\n",
    "    p, counts = np.unique(phonemes, return_counts=True)\n",
    "    zipped = list(zip(p.tolist(), counts.tolist()))\n",
    "\n",
    "    sorted_phonemes = np.flip(\n",
    "        np.sort(\n",
    "            np.array(zipped, dtype=[(\"phoneme\", \"U8\"),(\"count\", int)]),\n",
    "            axis=0,\n",
    "            order=\"count\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(30, 6))\n",
    "    plt.bar(*zip(*sorted_phonemes))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_axis)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a6c7d-26fa-413e-a25c-a0e46061c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_phoneme_chart(\n",
    "    phonemes=phoneme_list,\n",
    "    title=f\"Phoneme Frequency In {common_words.shape[0]} Common Words (Sorted)\", \n",
    "    x_axis=\"phoneme\", \n",
    "    y_axis=\"count\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d31fe-3dea-424e-a4fc-06fba1a518af",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_phoneme_chart(\n",
    "    phonemes=simple_phoneme_list,\n",
    "    title=f\"Phoneme Frequency In {common_words.shape[0]} Common Words (Sorted, No Vowel Emphasis)\", \n",
    "    x_axis=\"phoneme\", \n",
    "    y_axis=\"count\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2723780-5aac-42e3-b0c0-5b6fb58eaafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowel_list = [ phoneme for phoneme in phoneme_list if re.match('.*\\d', phoneme) ]\n",
    "\n",
    "show_phoneme_chart(\n",
    "    phonemes=vowel_list,\n",
    "    title=f\"Vowel Phoneme Frequency In {common_words.shape[0]} Common Words (Sorted)\", \n",
    "    x_axis=\"vowel phoneme\", \n",
    "    y_axis=\"count\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea05b1e-3e5b-46f6-8842-de8df43375f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_vowel_list = [ re.sub('\\d', \"\", vowel) for vowel in vowel_list ]\n",
    "\n",
    "show_phoneme_chart(\n",
    "    phonemes=simple_vowel_list,\n",
    "    title=f\"Vowel Phoneme Frequency In {common_words.shape[0]} Common Words (Sorted)\",\n",
    "    x_axis=f\"vowel phoneme (total: {len(np.unique(simple_vowel_list))})\", \n",
    "    y_axis=\"count\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b40fed8-96bc-4922-8714-edf82c727cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_simple_vowel_list = np.unique(simple_vowel_list)\n",
    "consonant_list = [ phoneme for phoneme in simple_phoneme_list if not np.isin(phoneme, unique_simple_vowel_list) ]\n",
    "\n",
    "show_phoneme_chart(\n",
    "    phonemes=consonant_list, \n",
    "    title=f\"Consonant Phoneme Frequency In {common_words.shape[0]} Common Words (Sorted)\", \n",
    "    x_axis=f\"consonant phoneme (total: {len(np.unique(consonant_list))})\", \n",
    "    y_axis=\"count\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7c8daf-fef3-4f3c-885a-e536d74c41b3",
   "metadata": {},
   "source": [
    "# Consonant Clusters\n",
    "\n",
    "In english consonants often appear next to each other, I should probably take some time trying to sus out the most common consonant clusters as well as the most common individual clusters\n",
    "\n",
    "### Analysis\n",
    "* Vowels can be the `primary stressed sound` (1) the `secondary stressed sound` (2) or an `unstressed sound` (0) in a word\n",
    "* Vowels that are stressed, seems to \"take\" the vowels surrounding them more than unstressed vowels\n",
    "* Consonants that appear at the beginning or end of a word seem to always clump together\n",
    "* \"S\" seems to stick to vowels more than consonants when in side words (it's almost like that \"s\" sound likes to slide into a nice vowel phoneme)\n",
    "\n",
    "Here are a few unique words I've found:\n",
    "\n",
    "* Puritan ('P', 'Y', 'UH1', 'R', 'AH0', 'T', 'AH0', 'N') the first 'AH0' gives up the 'R' to 'UH1' but also give up the 'T' to the second 'AH0'.\n",
    "  does that mean that internal unemphasized vowels are the least likely to clump with their consonant neighbors.\n",
    "* Forsaking ('F', 'AO0', 'R', 'S', 'EY1', 'K', 'IH0', 'NG') why don't the 'R' and 'S' clump here? It seems like the 'RS' composit cluster is potentially uncommon internally in a word.\n",
    "  I know it's not that weird at the end for words (force for example ends with 'RS')\n",
    "* Mildly ('M', 'AY1', 'L', 'D', 'L', 'IY0') Chosing how to split up 'L', 'D', 'L' is interesting.\n",
    "  My guess is that 'LD' is a pretty common consonant clusters (old, gold, mold), and maybe more common than 'DL' (fiddle, muddle)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c30eaa8-3ee0-4060-ac39-22ff1c55519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2p_en import G2p\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def is_vowel(phoneme):\n",
    "    return re.match('.*\\d', phoneme) is not None\n",
    "\n",
    "def is_consonant(phoneme):\n",
    "    return not is_vowel(phoneme)\n",
    "\n",
    "def initial_consonant_cluster(phoneme_list):\n",
    "    cluster = []\n",
    "    for phoneme in phoneme_list:\n",
    "        if not is_consonant(phoneme):\n",
    "            break\n",
    "        cluster.append(phoneme)\n",
    "\n",
    "    return tuple(cluster)\n",
    "\n",
    "def final_consonant_cluster(phoneme_list):\n",
    "    vowel_point = -1\n",
    "    final = []\n",
    "    for i, phoneme in enumerate(phoneme_list):\n",
    "        if not is_consonant(phoneme):\n",
    "            vowel_point = i\n",
    "            final = []\n",
    "            continue\n",
    "            \n",
    "        final.append(phoneme)\n",
    "\n",
    "    if vowel_point == -1:\n",
    "        return ()\n",
    "\n",
    "    return tuple(final)\n",
    "\n",
    "g2p = G2p()\n",
    "consonant_clusters_list = []\n",
    "for word in tqdm(common_words, desc=\"Building Phoneme Lists\"):\n",
    "    if word == \"\":\n",
    "        continue\n",
    "        \n",
    "    phoneme_list = g2p(word)\n",
    "    \n",
    "    initial = initial_consonant_cluster(phoneme_list)\n",
    "    if len(initial) > 0:\n",
    "        consonant_clusters_list.append(initial)\n",
    "\n",
    "    final = final_consonant_cluster(phoneme_list)\n",
    "    if len(final) > 0:\n",
    "        consonant_clusters_list.append(final)\n",
    "\n",
    "consonant_clusters = np.array(consonant_clusters_list, dtype=object)\n",
    "print(len(consonant_clusters))\n",
    "np.unique(consonant_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81776326-6a52-4707-b8fe-29aa1dc4fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dipthongs = [ \"/\".join(phoneme) for phoneme in consonant_clusters if len(phoneme) == 2 ]\n",
    "\n",
    "show_phoneme_chart(\n",
    "    phonemes=dipthongs, \n",
    "    title=f\"Diphthongs Phoneme Frequency In {common_words.shape[0]} Common Words (Sorted)\", \n",
    "    x_axis=f\"diphthong phoneme (total: {len(np.unique(dipthongs))})\", \n",
    "    y_axis=\"count\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769fcb69-309d-4b85-bfef-d8e57b4d3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tripthongs = [ \"/\".join(phoneme) for phoneme in consonant_clusters if len(phoneme) == 3 ]\n",
    "\n",
    "show_phoneme_chart(\n",
    "    phonemes=tripthongs, \n",
    "    title=f\"Triphthongs Phoneme Frequency In {common_words.shape[0]} Common Words (Sorted)\", \n",
    "    x_axis=f\"triphthongs phoneme (total: {len(np.unique(tripthongs))})\", \n",
    "    y_axis=\"count\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c3d02-fd55-448b-828f-1a9d762a762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quadriphthong = [ \"/\".join(phoneme) for phoneme in consonant_clusters if len(phoneme) == 4 ]\n",
    "\n",
    "show_phoneme_chart(\n",
    "    phonemes=quadriphthong, \n",
    "    title=f\"Quadriphthong Phoneme Frequency In {common_words.shape[0]} Common Words (Sorted)\", \n",
    "    x_axis=f\"quadriphthong phoneme (total: {len(np.unique(quadriphthong))})\", \n",
    "    y_axis=\"count\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70371e6-4934-4bf8-8cb3-8d20fb9f302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster5 = [ \"/\".join(phoneme) for phoneme in consonant_clusters if len(phoneme) > 4 ]\n",
    "print(\"there are no clusters longer than 3 phonemes: cluster5.length =\", len(cluster5))\n",
    "\n",
    "# show_phoneme_chart(\n",
    "#     phonemes=cluster5, \n",
    "#     title=f\"Long Consonant Cluster Phoneme Frequency In {common_words.shape[0]} Common Words (Sorted)\", \n",
    "#     x_axis=f\"consonant cluster (total: {len(np.unique(cluster5))})\", \n",
    "#     y_axis=\"count\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a558e-4212-4960-b0c8-54fc16776822",
   "metadata": {},
   "source": [
    "# Consonant Cluster Order\n",
    "\n",
    "It's clear to me that there's a pretty dramatic preference for certin phoneme clusters over others.\n",
    "Given that there are less than 100 diphthongs and triphthongs out of the possible 576 and 13,824 respectivly, not all clusters are created equal.\n",
    "The spelling system then should have a strong preference for representing common english sounds rather than trying to support all possible consonant clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3555a448-a6b1-4c04-b127-0ec09227ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_nth_consonant_chart(index, ordinal):\n",
    "    data = [ phoneme[index] for phoneme in consonant_clusters if len(phoneme) > index ]\n",
    "    show_phoneme_chart(\n",
    "        phonemes=data,\n",
    "        title=f\"{ordinal} Phoneme Frequency In Consonant Clusters In {common_words.shape[0]} Common Words (Sorted)\",\n",
    "        x_axis=f\"(consonant (total: {len(np.unique(data))})\", \n",
    "        y_axis=\"count\",\n",
    "    )\n",
    "\n",
    "show_nth_consonant_chart(0, \"First\")\n",
    "show_nth_consonant_chart(1, \"Second\")\n",
    "show_nth_consonant_chart(2, \"Third\")\n",
    "show_nth_consonant_chart(3, \"Fourth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1e65f-af46-45e5-9357-1fc5c1a304d3",
   "metadata": {},
   "source": [
    "# Consonant Cluster Corelation\n",
    "\n",
    "How often do given consonant phonemes appear with on another in consonant clusters in \n",
    "\n",
    "# Analysis\n",
    "\n",
    "So it looks like the figure i've seen that english has about 250 total unique consonant clusters is probably right.\n",
    "It's also crazy how much more often S and T appear together than any other consonant combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3116057f-5962-47eb-a5d5-8e2a42db6cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def draw_matrix(matrix, title, zero_identity=False):\n",
    "    \n",
    "    draw_matrix = np.zeros(shape=matrix.shape, dtype=float)\n",
    "    for y in range(matrix.shape[0]):\n",
    "        for x in range(matrix.shape[1]):\n",
    "            draw_matrix[x,y] = matrix[x,y]\n",
    "        if zero_identity:\n",
    "            draw_matrix[y, y] = 0\n",
    "            \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(draw_matrix, interpolation='none')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(orientation='vertical')\n",
    "    plt.xticks(np.arange(0, count), labels=unique_consonant_list)\n",
    "    plt.yticks(np.arange(0, count), labels=unique_consonant_list)\n",
    "    plt.show()\n",
    "\n",
    "# get all the consonant phonemes sorted by frequency\n",
    "consonants, counts = np.unique([ consonant for consonant in consonant_clusters if len(consonant) == 1 ], return_counts=True)\n",
    "zipped_consonants_list = list(zip(consonants.tolist(), counts.tolist()))\n",
    "sorted_consonants_list = np.flip(\n",
    "    np.sort(\n",
    "        np.array(zipped_consonants_list, dtype=[(\"consonant\", \"U8\"),(\"count\", int)]),\n",
    "        axis=0,\n",
    "        order=\"count\",\n",
    "    )\n",
    ")\n",
    "\n",
    "unique_consonant_list = np.array([ consonant[0] for consonant in sorted_consonants_list ])\n",
    "count = unique_consonant_list.shape[0]\n",
    "np_matrix = np.zeros(shape=(count, count), dtype=float)\n",
    "\n",
    "for cluster in consonant_clusters:\n",
    "    for i, c0 in enumerate(cluster):\n",
    "        for c1 in cluster[i:]:\n",
    "            x = np.where(unique_consonant_list == (c1))[0]\n",
    "            y = np.where(unique_consonant_list == (c0))[0]\n",
    "            np_matrix[x,y] += 1\n",
    "            np_matrix[y,x] += 1\n",
    "\n",
    "# do some quick validation\n",
    "for y in range(count):\n",
    "    for x in range(count):\n",
    "        assert np_matrix[x,y] <= np_matrix[y,y], f\"m[{x}, {y}] = {np_matrix[x,y]} but m[{y}, {y}] = {np_matrix[y,y]}\"\n",
    "        assert np_matrix[x,y] == np_matrix[y,x], f\"m[{x}, {y}] = {np_matrix[x,y]} but m[{y}, {x}] = {np_matrix[y,x]}\"\n",
    "            \n",
    "draw_matrix(np_matrix, \"Consonant Correlation within Clusters\", zero_identity=True)\n",
    "\n",
    "# normalize the matrix base on the diaganal\n",
    "np_matrix_norm = np.zeros(shape=(count, count), dtype=float)\n",
    "for y in range(count):\n",
    "    for x in range(count):\n",
    "        np_matrix_norm[x,y] = np_matrix[x,y] / np_matrix[y,y]\n",
    "\n",
    "    # quick validation check again\n",
    "    assert np_matrix_norm[y,y] == 1.0\n",
    "\n",
    "draw_matrix(np_matrix_norm, \"Normalized Consonant Correlation within Clusters\", zero_identity=True)\n",
    "\n",
    "# identify zeros\n",
    "total = 0.0\n",
    "non_zero = 0.0\n",
    "np_matrix_bin = np.zeros(shape=(count, count), dtype=float)\n",
    "for y in range(count):\n",
    "    for x in range(count):\n",
    "        total += 1\n",
    "        if np_matrix[x,y] > 0.01:\n",
    "            non_zero += 1\n",
    "            np_matrix_bin[x,y] = 1\n",
    "\n",
    "draw_matrix(np_matrix_bin, f\"Binary Consonant Correlation within Clusters ({(non_zero/total)*100:.2f}% covered)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4557cfa3-cf6f-4327-9024-97827d3af0b3",
   "metadata": {},
   "source": [
    "# Encoding Strategies\n",
    "\n",
    "One of the key things to take into account when crafting an encoding is to measure how effective the encoding is comunicating english words.\n",
    "This is espeically important given how complex english consonant clusters can get.\n",
    "For examples, in the 25k common words I found 1 consonant cluster that included 6 unique consonant sounds.\n",
    "Therefor, a good written language will need to support the complex nature of english consonant clusters.\n",
    "\n",
    "There are a couple metrics I want to use to judge how good a given encoding is for this representation.\n",
    "I can represent my written system using a series of point so developing an abstract representation of the encoding first and then inform the visual design.\n",
    "\n",
    "### distinctivness\n",
    "This measures how distinct all the given consonant cluster encodings are from each other.\n",
    "In the best case, all consonant clustesrs are represented by totally distinct encodings.\n",
    "In the worst case, all consonant clusters are represented by the exact same encoding.\n",
    "Distinctiveness is calculated using the following formulas:\n",
    "\n",
    "\\begin{align*}\n",
    "D(E, C) &= \\frac{\\sum_{w \\in C} U(w, E, C)}{\\sum \\#P(w)} \\\\\n",
    "U(w, E, C) &= \\sum_{p \\in P(w)} Q(p) \\\\\n",
    "Q(p) &= \\begin{cases}\n",
    "    0 & \\text{if } E(p) \\in \\bigcup \\{ E(p_0) \\mid p_0 \\in N(p, C) \\} \\\\\n",
    "    1 & \\text{otherwise}\n",
    "\\end{cases} \\\\\n",
    "N(p, C) &= \\bigcup \\{ P(w) | w \\in C \\} - p\n",
    "\\end{align*}\n",
    "\n",
    "Where D calculates the distinctivness of an encoder E given a corpus of text C.\n",
    "E is the encoding function which gives and encoding value for each phoneme.\n",
    "P(w) returns *JUST* the consonat phonemes of a given word, consonant clusters are represented by a single phonemes.\n",
    "U(w, E, C) is the uniquness score of a word(w) given an encoder(E) and a text corpus(C).\n",
    "Q(p, C) is the uniquenes score of a single phonemes(p) encoding given a text corpus(C).\n",
    "N(p, C) is the set of all unique phonemes in a text corpus(C) minus the given phoneme(p).\n",
    "#a is the numer of element in the list a\n",
    "\n",
    "### visual complexity\n",
    "Visual complexity is a measure of how complex it is to parse a given consolant cluster.\n",
    "Lower visual complexity is better especially for common clusters that appear often.\n",
    "Visual complexity tends to increase as the number of points in an encoding increase, however sometimes denser representations can actually be more visually clear.\n",
    "Visual complexity is calculated using the following formulas:\n",
    "\n",
    "\\begin{align*}\n",
    "V(E, C) = Σ F(w, E) | w ∈ C  \n",
    "\n",
    "F(w, E) = Σ G(E(p)) | p ∈ w \n",
    "\\end{align*}\n",
    "\n",
    "Where V(E, C) calculates the visual complexity of characters encoding given an encoder E, and a corpus of text C.\n",
    "F(w, E) is the visual complexity of the word.\n",
    "G(e) computs the visual complexity score for a given phoneme encoding.\n",
    "E(p) takes a phoneme from a word and produces the encoding for that phoneme.\n",
    "\n",
    "### visual audio coherence\n",
    "Encodings may have good distintivness and visual clarity.\n",
    "However, writen language reflect the physical reality of producing sound using our vocal cords.\n",
    "Representing similar sounds with similar symboles will likely make the writing system easier to learn and use.\n",
    "Visual audio coherence can be calculated using the following.\n",
    "\n",
    "\\begin{align*}\n",
    "r = (\\#T D_{ep} - D_e*D_p / \\sqrt{ (\\#T D_{es} - D_e^2) * (\\#T D_{ps} - D_p^2)})\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "D_e = Σ e(t0, t1) | t ∈ T\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "D_es = Σ e(t0, t1)^2 | t ∈ T\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "D_p = Σ p(t0, t1) | t ∈ T\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "D_ps = Σ p(t0, t1)^2 | t ∈ T\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "D_ep = Σ e(t0, t1) * p(t0, t1) | t ∈ T\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "T = { (p0, p1) | p0 ∈ { p | p ∈ C }, p1 ∈ { p | p ∈ C } }\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "`r` is the Pearson correlation coefficient and calculates the correlation between phoneme encoding and phoneme production.  \n",
    "`e` calculates the distance between phoneme embeddings and can produce a vector for a more robust representation.  \n",
    "`p` calculates the distance between phoneme production and can produce a vector for a more robust representation.  \n",
    "`D_e` is the sum of all embedding distances for all tuples in T.  \n",
    "`D_es` is the sume of all squared embedding distances for all tuples in T.  \n",
    "`D_p` is the sum of all phoneme production distances for all tuples in T.  \n",
    "`D_ps` is the sum of all phoneme production distances for all tuples in T.  \n",
    "`T` is the set of all unique tuples where each tuple represents on possible combination of 2 phonemes from a given corpus of text.  \n",
    "\n",
    "\n",
    "# Thoughts\n",
    "\n",
    "A lot of these ideas can proabbly be tied back into information theory.\n",
    "I should dig into that and see what I can find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a005a558-9b4a-4b59-8ed8-32d0bbbef43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 0 - 1\n",
    "# 2 - 3\n",
    "# 4 - 5\n",
    "# 6 - 7\n",
    "# 8 - 9\n",
    "\n",
    "mapping_1 = {\n",
    "    \"R\": [0],\n",
    "    \"P\": [1],\n",
    "    \"N\": [2],\n",
    "    \"S\": [3],\n",
    "    \"K\": [4],\n",
    "    \"D\": [5],\n",
    "    \"L\": [6],\n",
    "    \"T\": [7],\n",
    "    \"Z\": [8],\n",
    "    \"M\": [9],\n",
    "    \"B\": [0, 2],\n",
    "    \"F\": [1, 2],\n",
    "    \"H\": [3, 2],\n",
    "    \"G\": [4, 2],\n",
    "    \"V\": [5, 2],\n",
    "    \"W\": [6, 2],\n",
    "    \"J\": [7, 2],\n",
    "    \"C\": [8, 2],\n",
    "    \"Y\": [9, 2],\n",
    "}\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
